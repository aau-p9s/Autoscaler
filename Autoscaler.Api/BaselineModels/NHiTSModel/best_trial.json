{
    "number": 1,
    "value": 0.09550931288487693,
    "params": {
        "input_chunk_length": 166,
        "output_chunk_length": 23,
        "dropout": 0.22718842596315175,
        "activation": "ReLU",
        "num_blocks": 2,
        "num_layers": 1,
        "generic_architecture": true,
        "num_stacks": 3
    },
    "trials": 14,
    "failed_trials": 0
}